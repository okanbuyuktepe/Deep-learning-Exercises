{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sonar.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNi9i6QXWtQK0nWfy/LeJoX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/okanbuyuktepe/Deep-learning-Exercises/blob/master/sonar.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGiIKhWe0o8t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from pandas import read_csv\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.pipeline import Pipeline"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCydMVWDT0jB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed = 7\n",
        "numpy.random.seed(seed)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOfpM3aCUExD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load dataset\n",
        "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/undocumented/connectionist-bench/sonar/sonar.all-data'\n",
        "dataframe = read_csv(url, header=None)\n",
        "dataset = dataframe.values\n",
        "# split into input and output variables\n",
        "X = dataset[:,0:60].astype(float)\n",
        "Y = dataset[:,60]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Ltob2__UfTb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Encode class values as integers\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(Y)\n",
        "encoded_Y = encoder.transform(Y)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DvmqBc4U48N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# baseline model\n",
        "def create_baseline():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(60, input_dim=60, kernel_initializer='normal', activation='relu'))\n",
        "  model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ymkf5B57WPGr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7ab913bc-d195-42f3-83f4-cbe2186cd0cb"
      },
      "source": [
        "# evaluate model with standardized dataset\n",
        "estimator = KerasClassifier(build_fn=create_baseline, epochs=100, batch_size=5, verbose=0)\n",
        "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
        "results = cross_val_score(estimator, X, encoded_Y, cv=kfold)\n",
        "print('Baseline: %2.f%% (%.2f%%)' % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Baseline: 79% (9.85%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKqyf6x1XIPw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "89a419f9-3747-4097-9c27-5af703a1325f"
      },
      "source": [
        "# Improve Performance with Data Preparation\n",
        "'''\n",
        "The pipeline is a wrapper that executes one or more models within a pass of the cross-validation procedure.\n",
        "An effective data preparation scheme for tabular data when building neural network models is standardization\n",
        "This is where the data is rescaled such that the mean value for each attribute is 0 and the standard\n",
        "deviation is 1.\n",
        "''' \n",
        "# Binary Classification with Sonar Dataset: Standardized\n",
        "import numpy\n",
        "from pandas import read_csv\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/undocumented/connectionist-bench/sonar/sonar.all-data'\n",
        "dataframe = read_csv(url, header = None)\n",
        "dataset = dataframe.values\n",
        "X = dataset[:,0:60].astype(float)\n",
        "Y = dataset[:,60]\n",
        "# encode class values as integers\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(Y)\n",
        "encoded_Y = encoder.transform(Y)\n",
        "# baseline model\n",
        "def create_baseline():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(60, input_dim=60, kernel_initializer='normal', activation='relu'))\n",
        "  model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  return model\n",
        "# evaluate baseline model with standardized dataset\n",
        "estimators = []\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=create_baseline, epochs=100, batch_size=5, verbose=0)))\n",
        "pipeline = Pipeline(estimators)\n",
        "kfold = StratifiedKFold(n_splits=10, shuffle= True, random_state=seed)\n",
        "results = cross_val_score(pipeline, X, encoded_Y, cv=kfold)\n",
        "print('Standardized: %.2f%% (%.2f%%)' % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Standardized: 83.14% (8.63%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKMPbJO-47ti",
        "colab_type": "text"
      },
      "source": [
        "Tuning Layers and Neurons in The Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yovgvr4C5FD6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "58f7612e-cdb6-46e1-b0cc-e8b70b97eb0b"
      },
      "source": [
        "# Evaluate a smaller network\n",
        "# we take our baseline model with 60 neurons in the hidden layer and reduce it by half to 30.\n",
        "# Binary Classification with Sonar Dataset: Standardized Smaller\n",
        "import numpy\n",
        "from pandas import read_csv\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/undocumented/connectionist-bench/sonar/sonar.all-data'\n",
        "dataframe = read_csv(url, header = None)\n",
        "dataset = dataframe.values\n",
        "X = dataset[:,0:60].astype(float)\n",
        "Y = dataset[:,60]\n",
        "# encode class values as integers\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(Y)\n",
        "encoded_Y = encoder.transform(Y)\n",
        "# baseline model\n",
        "def create_baseline():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(30, input_dim=60, kernel_initializer='normal', activation='relu'))\n",
        "  model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  return model\n",
        "# evaluate baseline model with standardized dataset\n",
        "estimators = []\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=create_baseline, epochs=100, batch_size=5, verbose=0)))\n",
        "pipeline = Pipeline(estimators)\n",
        "kfold = StratifiedKFold(n_splits=10, shuffle= True, random_state=seed)\n",
        "results = cross_val_score(pipeline, X, encoded_Y, cv=kfold)\n",
        "print('Standardized: %.2f%% (%.2f%%)' % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Standardized: 84.57% (5.86%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DJ3jUAKBTSo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "767561e3-338d-44d0-f429-1456e9dcc266"
      },
      "source": [
        "# Evaluate a Larger Network\n",
        "# Here, we add one new layer (one line) to the network that introduces another hidden layer with 30 neurons after the \n",
        "# first hidden layer.\n",
        "'''\n",
        "The idea here is that the network is given the opportunity to model all input variables\n",
        "before being bottlenecked and forced to halve the representational capacity, much like we did in\n",
        "the experiment above with the smaller network. Instead of squeezing the representation of the\n",
        "inputs themselves, we have an additional hidden layer to aid in the process.\n",
        "'''\n",
        "# Binary Classification with Sonar Dataset: Standardized Larger\n",
        "import numpy\n",
        "from pandas import read_csv\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/undocumented/connectionist-bench/sonar/sonar.all-data'\n",
        "dataframe = read_csv(url, header = None)\n",
        "dataset = dataframe.values\n",
        "X = dataset[:,0:60].astype(float)\n",
        "Y = dataset[:,60]\n",
        "# encode class values as integers\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(Y)\n",
        "encoded_Y = encoder.transform(Y)\n",
        "# baseline model\n",
        "def create_baseline():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(60, input_dim=60, kernel_initializer='normal', activation='relu'))\n",
        "  model.add(Dense(30,  kernel_initializer='normal', activation='relu'))\n",
        "  model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  return model\n",
        "# evaluate baseline model with standardized dataset\n",
        "estimators = []\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=create_baseline, epochs=100, batch_size=5, verbose=0)))\n",
        "pipeline = Pipeline(estimators)\n",
        "kfold = StratifiedKFold(n_splits=10, shuffle= True, random_state=seed)\n",
        "results = cross_val_score(pipeline, X, encoded_Y, cv=kfold)\n",
        "print('Standardized: %.2f%% (%.2f%%)' % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Standardized: 85.07% (5.57%)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}